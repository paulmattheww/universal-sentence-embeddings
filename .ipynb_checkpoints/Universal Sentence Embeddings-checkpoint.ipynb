{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview of Applications in Natural Language Processing\n",
    "\n",
    "Paul M. Washburn\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Universal Sentence Embedding** is a state-of-the-art practice that emerged in 2018 as an effective practice in natural language machine learning tasks.\n",
    "\n",
    "Both word & sentence embeddings are transfer learning techniques that convert natural language text into fixed-length dense vectors of real numbers that represent the original data in a more [contextually aware manner](https://aclweb.org/aclwiki/Distributional_Hypothesis).  Universal embeddings are of interest to the community due to the fact that machine learning algorithms in general, and in particular neural networks, play nicely with the dense numeric vectors produced by the embedding process.\n",
    "\n",
    "Over the last couple of years there has been a movement towards **Universal Embeddings** that are pre-trained and ready-for-use in downstream machine learning workflows.  Universal embeddings often confer a qualitative improvement in NLP classification (and similar) tasks due to the fact that they are derived from a large corpus of examples.\n",
    "\n",
    "Downstream workflows that might benefit from universal embeddings include:\n",
    "\n",
    "- Sentiment analysis\n",
    "- Classification tasks\n",
    "- Translation tasks\n",
    "- Unsupervised learning\n",
    "- Visualization \n",
    "\n",
    "The enrichment of natural language text data via embeddings has had considerable success, so we will explore the reasons for that success as well as some applications of the technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Since sentence embeddings are an extension on the concept of *Word Embeddings* let us briefly examine what they are.  \n",
    "\n",
    "Both word & sentence embeddings are a form of [*Transfer Learning*](https://en.wikipedia.org/wiki/Transfer_learning), or the transference of knowledge learned from one domain to another (related) domain.  For example, a model built to recognize cars in a traffic video stream could be re-used in for a model built for recognizing trucks. \n",
    "\n",
    "---------------------------------------------------------------\n",
    "## What Is An *Embedding*?\n",
    "\n",
    "[Google's TensorFlow documentation](https://www.tensorflow.org/guide/embedding) states: *An embedding is a mapping from discrete objects, such as words, to vectors of real numbers.*\n",
    "\n",
    "```python\n",
    "## For example, a 300-dimensional embedding for English words could include:\n",
    "blue:  (0.01359, 0.00075997, 0.24608, ..., -0.2524, 1.0048, 0.06259)\n",
    "blues:  (0.01396, 0.11887, -0.48963, ..., 0.033483, -0.10007, 0.1158)\n",
    "orange:  (-0.24776, -0.12359, 0.20986, ..., 0.079717, 0.23865, -0.014213)\n",
    "oranges:  (-0.35609, 0.21854, 0.080944, ..., -0.35413, 0.38511, -0.070976)\n",
    "```\n",
    "\n",
    "*Embedding functions are the standard and effective way to transform such discrete input objects into useful continuous vectors.*\n",
    "\n",
    "*The individual dimensions in these vectors have no inherent meaning.  The overall patterns of location and distance between vectors, however, are highly valuable in machine learning tasks.  For example the Euclidean distance or angle between vectors can be easily derived for a sort of nearest-neighbor analysis:*\n",
    "\n",
    "```python\n",
    "blue:  (red, 47.6°), (yellow, 51.9°), (purple, 52.4°)\n",
    "blues:  (jazz, 53.3°), (folk, 59.1°), (bluegrass, 60.6°)\n",
    "orange:  (yellow, 53.5°), (colored, 58.0°), (bright, 59.9°)\n",
    "oranges:  (apples, 45.3°), (lemons, 48.3°), (mangoes, 50.4°)\n",
    "```\n",
    "---------------------------------------------------------------\n",
    "\n",
    "## A Brief History of Word Embeddings\n",
    "\n",
    "The concept of word embeddings began with two projects by Google and Stanford called [word2vec](https://github.com/dav/word2vec/) and [GloVe - Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/).  Both approaches are unsupervised approaches that are based on the [distributional hypothesis](https://aclweb.org/aclwiki/Distributional_Hypothesis) (words that co-occur tend to have similar meanings).  These approaches were superceded by [FastText](https://github.com/facebookresearch/fastText) and [ELMo](http://allennlp.org/elmo) that have greater tolerance for out-of-vocabulary n-grams and character features.  These advancements appear to have spurred an increased rate of innovation in this space in recent months, leading to exciting advancements such as universal embeddings. All this work naturally culminates on the topic of this presentation, [Google's Universal Sentence Encoder](https://arxiv.org/pdf/1803.11175.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Word Embeddings to Sentence Embeddings\n",
    "\n",
    "There are many competing schemes for taking word embeddings and transforming them into sentence embeddings.  The simple heuristic of taking a sentence's word vectors' average is generally accepted as a strong approach in spite of its simplicity.  However there is a lot of exciting research in this area that includes supervised, unsupervised approaches, and ensemble approaches.  \n",
    "\n",
    "## Google's Universal Sentence Encoder\n",
    "\n",
    "In early 2018 Google made available a universal sentence encoder transformer that has been trained on many observations from a variety of sources & tasks in order to get broad enough coverage to be universally useful. This tool makes it easy for data scientists to access sentence-level embeddings as easy as it has historically been to lookup individual word embeddings.  The embeddings returned by this free-to-use-tool are approximately normalized, which is ideal for use in machine learning tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications\n",
    "\n",
    "## `\"Hello World\"` Demonstration of Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ON THE DUTY OF CIVIL DISOBEDIENCE\\n',\n",
       " 'WALDEN\\n',\n",
       " 'Economy\\n',\n",
       " 'When I wrote the following pages, or rather the bulk of them, I lived\\n',\n",
       " 'alone, in the woods, a mile from any neighbor, in a house which I had\\n',\n",
       " 'built myself, on the shore of Walden Pond, in Concord, Massachusetts,\\n',\n",
       " 'and earned my living by the labor of my hands only. I lived there two\\n',\n",
       " 'years and two months. At present I am a sojourner in civilized life\\n',\n",
       " 'again.\\n',\n",
       " 'I should not obtrude my affairs so much on the notice of my readers if\\n',\n",
       " 'very particular inquiries had not been made by my townsmen concerning\\n',\n",
       " 'my mode of life, which some would call impertinent, though they do not\\n',\n",
       " 'appear to me at all impertinent, but, considering the circumstances,\\n',\n",
       " 'very natural and pertinent. Some have asked what I got to eat; if I did\\n',\n",
       " 'not feel lonesome; if I was not afraid; and the like. Others have been\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/thoreau-walden.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [l for l in lines if l != \"\\n\"]\n",
    "lines = [l for l in lines if len(l) >]\n",
    "lines[25:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText & CountVectorizer & TfidfVectorizer as a baseline\n",
    "\n",
    "\n",
    "def fetch_universal_sentence_embeddings(messages, verbose=0):\n",
    "    \"\"\"Fetches universal sentence embeddings from Google's\n",
    "    research paper https://arxiv.org/pdf/1803.11175.pdf.\n",
    "    \n",
    "    INPUTS:\n",
    "    RETURNS:\n",
    "    \"\"\"\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed = hub.Module(module_url)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(messages))\n",
    "        embeddings = list()\n",
    "        for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "            if verbose:\n",
    "                print(\"Message: {}\".format(messages[i]))\n",
    "                print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "                message_embedding_snippet = \", \".join(\n",
    "                    (str(x) for x in message_embedding[:3]))\n",
    "                print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "            embeddings.append(message_embedding)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embeddings = fetch_universal_sentence_embeddings(lines[25:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03612850233912468,\n",
       " -0.04058030992746353,\n",
       " -0.01834092102944851,\n",
       " 0.019077610224485397,\n",
       " 0.08532124012708664,\n",
       " -0.060324832797050476,\n",
       " 2.1142602690815693e-06,\n",
       " 0.0012475283583626151,\n",
       " -0.05353572219610214,\n",
       " -0.045716796070337296,\n",
       " 0.02887057326734066,\n",
       " -0.06979456543922424,\n",
       " 0.05494796857237816,\n",
       " 0.02506193332374096,\n",
       " -0.09119703620672226,\n",
       " -0.0011676112189888954,\n",
       " -0.04826129600405693,\n",
       " 0.05431929603219032,\n",
       " 0.01620793342590332,\n",
       " -0.06765597313642502,\n",
       " -0.008597459644079208,\n",
       " -0.07260719686746597,\n",
       " -0.06897539645433426,\n",
       " 0.09442207962274551,\n",
       " 0.027198338881134987]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on `ARTHUR` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/washburp/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>desc_of_operations</th>\n",
       "      <th>website</th>\n",
       "      <th>bus_eff_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14507</td>\n",
       "      <td>c5506</td>\n",
       "      <td>SUBMITTED BY COMMERCIAL INSURANCE SERVICES INC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956-01-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14514</td>\n",
       "      <td>c7720</td>\n",
       "      <td>1111 audit: This policyholder holder is a muni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956-01-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14543</td>\n",
       "      <td>c0251</td>\n",
       "      <td>OWN AND MAINTIAN AN IRRIGATION CANAL THAT DELI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-08-19 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14545</td>\n",
       "      <td>c0251</td>\n",
       "      <td>Website: www.northsterling.org The North Sterl...</td>\n",
       "      <td>https://www.northsterling.org/</td>\n",
       "      <td>1956-01-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14551</td>\n",
       "      <td>c5506</td>\n",
       "      <td>UNDER LA JARA TOWN GOVERNMENT IN THE WHITE PAG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956-01-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id target                                 desc_of_operations  \\\n",
       "0  14507  c5506  SUBMITTED BY COMMERCIAL INSURANCE SERVICES INC...   \n",
       "1  14514  c7720  1111 audit: This policyholder holder is a muni...   \n",
       "2  14543  c0251  OWN AND MAINTIAN AN IRRIGATION CANAL THAT DELI...   \n",
       "3  14545  c0251  Website: www.northsterling.org The North Sterl...   \n",
       "4  14551  c5506  UNDER LA JARA TOWN GOVERNMENT IN THE WHITE PAG...   \n",
       "\n",
       "                          website           bus_eff_date  \n",
       "0                             NaN  1956-01-01 00:00:00.0  \n",
       "1                             NaN  1956-01-01 00:00:00.0  \n",
       "2                             NaN  1975-08-19 00:00:00.0  \n",
       "3  https://www.northsterling.org/  1956-01-01 00:00:00.0  \n",
       "4                             NaN  1956-01-01 00:00:00.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in training data from ARTHUR competition\n",
    "arthur = pd.read_csv(\"data/paul_arthur_data/train_df.csv\")\n",
    "arthur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562988, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342706, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur = arthur.drop_duplicates(subset=\"desc_of_operations\")\n",
    "arthur = arthur.loc[~arthur.desc_of_operations.isnull()]\n",
    "arthur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X, y = arthur.desc_of_operations.astype(str).tolist(), arthur.target.astype(str)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=7, stratify=y, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embed_train = fetch_universal_sentence_embeddings(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(embed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def multiclass_confusion_matrix(y, yhat, model_name='unspecified',\n",
    "                               verbose=1):\n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------------\n",
    "    y: true labels \n",
    "    yhat: predicted labels \n",
    "    model_name: name of model for printing\n",
    "    \n",
    "    Outputs:\n",
    "    ------------------------------------------------------\n",
    "    cm: confusion matrix (easily readable)\n",
    "    metrics: dict of metrics on multiclass classification\n",
    "    '''\n",
    "    # organize confusion matrix from sklearn into readable format\n",
    "    sk_confusion_matrix = confusion_matrix(y, yhat).transpose()#; print(sk_confusion_matrix)\n",
    "    \n",
    "    # put in pd.DataFrame and add names\n",
    "    cm = pd.DataFrame(sk_confusion_matrix)\n",
    "    IX = ['Test_' + str(i+1) for i in cm.index]\n",
    "    COLS = ['Condition_' + str(i+1) for i in cm.columns]\n",
    "    cm.columns, cm.index = COLS, IX\n",
    "    \n",
    "    # add totals\n",
    "    cm['Total'] = cm.sum(axis=1)\n",
    "    cm.loc['Total'] = cm.sum(axis=0)\n",
    "    \n",
    "    # get performance scores\n",
    "    N = cm.loc['Total', 'Total']\n",
    "    TP = np.diag(cm.loc[IX, COLS]).sum()\n",
    "    ACC = np.divide(TP, N)\n",
    "    MCR = 1 - ACC\n",
    "    \n",
    "    if verbose:\n",
    "        print('''\n",
    "        Confusion Matrix for Model: %s\n",
    "        ------------------------------------------------------''' %model_name)\n",
    "        print(cm)\n",
    "        print('''\n",
    "        Metrics for Model: %s\n",
    "        ------------------------------------------------------\n",
    "        Accuracy Rate = %.5f\n",
    "        Misclassification Rate = %.5f\n",
    "        ''' %(model_name, ACC, MCR))\n",
    "        return None\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def train_val_metrics(grid, X_train, X_val, y_train, y_val):\n",
    "    # check train data\n",
    "    y_pred_train, y_pred_val = grid.predict(X_train), grid.predict(X_val)\n",
    "\n",
    "    train_acc, train_f1 = accuracy_score(y_pred_train, y_train), f1_score(y_pred_train, y_train, average='macro')\n",
    "    print('''\n",
    "    Training Accuracy = %.4f\n",
    "    Training F1 Score = %.4f\n",
    "    ''' %(train_acc, train_f1))\n",
    "\n",
    "    _ = multiclass_confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "    skplt.metrics.plot_roc_curve(y_train, grid.predict_proba(X_train))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Training Results')\n",
    "    plt.show()\n",
    "    \n",
    "    # check validation data \n",
    "    val_acc, val_f1 = accuracy_score(y_pred_val, y_val), f1_score(y_pred_val, y_val, average='macro')\n",
    "\n",
    "    print('''\n",
    "    Validation Accuracy = %.4f\n",
    "    Validation F1 Score = %.4f\n",
    "    ''' %(val_acc, val_f1))\n",
    "\n",
    "    _ = multiclass_confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "    skplt.metrics.plot_roc_curve(y_val, grid.predict_proba(X_val))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Validation Results')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embed_val = fetch_universal_sentence_embeddings(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training Accuracy = 0.6212\n",
      "    Training F1 Score = 0.4579\n",
      "    \n",
      "\n",
      "        Confusion Matrix for Model: unspecified\n",
      "        ------------------------------------------------------\n",
      "          Condition_1  Condition_2  Condition_3  Condition_4  Condition_5  \\\n",
      "Test_1            137            1            0            0           17   \n",
      "Test_2              1          111            1            1            6   \n",
      "Test_3              1            4          177            0            0   \n",
      "Test_4              0            0            0           49            0   \n",
      "Test_5             23            7            2            1          632   \n",
      "Test_6              0            0            0            0            0   \n",
      "Test_7             15          147           17            2           13   \n",
      "Test_8             46            6            2            0           17   \n",
      "Test_9              0            0            0            0            0   \n",
      "Test_10             0            1            0            0            0   \n",
      "Test_11             1            5            1            7            0   \n",
      "Test_12            10            0            1            0            1   \n",
      "Test_13             0            0            0            0            0   \n",
      "Test_14             1            1            0            0            0   \n",
      "Test_15             0            0            0            0            0   \n",
      "Test_16             0            0            0            0            0   \n",
      "Test_17             0            0            0            0            0   \n",
      "Test_18             0            0            0            0            0   \n",
      "Test_19             0            0            0            0            1   \n",
      "Test_20             0            0            0            0            0   \n",
      "Test_21             0            0            0            0            1   \n",
      "Test_22             0            0            0            0            0   \n",
      "Test_23             0            0            0            0            0   \n",
      "Test_24             0            0            0            0            0   \n",
      "Test_25             0            0            0            0            0   \n",
      "Test_26             0            1            0            0            0   \n",
      "Test_27             0            0            0            0            0   \n",
      "Test_28             0            1            0            0            0   \n",
      "Test_29             0            0            0            0            0   \n",
      "Test_30             0            0            0            0            0   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "Test_265            5            2            1            0            5   \n",
      "Test_266            0            0            0            1            1   \n",
      "Test_267            0            0            0            0            0   \n",
      "Test_268            0            0            0            0            0   \n",
      "Test_269            0            0            0            0            0   \n",
      "Test_270            6            1            0            0            0   \n",
      "Test_271            0            0            0            0            0   \n",
      "Test_272            0            0            0            0            0   \n",
      "Test_273            0            0            0            0            0   \n",
      "Test_274            0            0            0            0            0   \n",
      "Test_275            0            0            0            0            0   \n",
      "Test_276            0            0            0            0            0   \n",
      "Test_277            0            0            0            0            0   \n",
      "Test_278            0            0            0            0            0   \n",
      "Test_279            0            0            0            0            0   \n",
      "Test_280            0            0            0            0            0   \n",
      "Test_281            0            0            0            0            0   \n",
      "Test_282            1            0            0            0            0   \n",
      "Test_283            0            0            0            0            0   \n",
      "Test_284            0            0            0            0            0   \n",
      "Test_285            0            0            0            0            0   \n",
      "Test_286            0            0            0            0            0   \n",
      "Test_287            0            0            0            0            0   \n",
      "Test_288            0            0            0            0            0   \n",
      "Test_289            0            0            0            0            0   \n",
      "Test_290            0            0            0            0            0   \n",
      "Test_291            0            0            0            0            0   \n",
      "Test_292            0            0            0            0            0   \n",
      "Test_293            0            0            0            0            0   \n",
      "Total             306          332          218           74          829   \n",
      "\n",
      "          Condition_6  Condition_7  Condition_8  Condition_9  Condition_10  \\\n",
      "Test_1              0            2           10            0             0   \n",
      "Test_2              0           19            1            0             1   \n",
      "Test_3              1            4            0            0             7   \n",
      "Test_4              0            1            0            0             0   \n",
      "Test_5              0           24            5            2             0   \n",
      "Test_6            201            5            0            0             0   \n",
      "Test_7             17         2162           22          110             8   \n",
      "Test_8              1           25         3361            8             2   \n",
      "Test_9              0            4            0           15             0   \n",
      "Test_10             0            0            0            0            23   \n",
      "Test_11            15          294            5           22             0   \n",
      "Test_12             0            1           83            2             0   \n",
      "Test_13             0            3            6            0             0   \n",
      "Test_14             0           13            7            1             0   \n",
      "Test_15             0            1            0            0             0   \n",
      "Test_16             0            0            1            0             0   \n",
      "Test_17             0            0            0            0             0   \n",
      "Test_18             0            0            0            0             0   \n",
      "Test_19             0            0            0            0             0   \n",
      "Test_20             0            0            0            0             0   \n",
      "Test_21             0            0            0            0             0   \n",
      "Test_22             1            0            0            0             0   \n",
      "Test_23             0            0            0            0             0   \n",
      "Test_24             0            0            0            0             0   \n",
      "Test_25             0            0            0            0             0   \n",
      "Test_26             0            0            0            0             0   \n",
      "Test_27             0            0            0            0             0   \n",
      "Test_28             0            0            0            0             2   \n",
      "Test_29             0            0            0            0             0   \n",
      "Test_30             0            0            0            0             0   \n",
      "...               ...          ...          ...          ...           ...   \n",
      "Test_265            3           23           24            0             2   \n",
      "Test_266            0            1            2            1             0   \n",
      "Test_267            0            3            2            1             0   \n",
      "Test_268            0            0            0            0             0   \n",
      "Test_269            0            0            0            0             0   \n",
      "Test_270            0            4          229           10             0   \n",
      "Test_271            0            0            0            0             0   \n",
      "Test_272            0            0            0            0             0   \n",
      "Test_273            0            0            0            0             0   \n",
      "Test_274            0            0            0            0             0   \n",
      "Test_275            0            0            2            0             0   \n",
      "Test_276            0            0            0            0             0   \n",
      "Test_277            1            0            0            0             0   \n",
      "Test_278            0            0            0            0             0   \n",
      "Test_279            0            0            1            0             0   \n",
      "Test_280            0            0           51            1             0   \n",
      "Test_281            0            0            0            1             0   \n",
      "Test_282            0            0            0            0             0   \n",
      "Test_283            0            0            0            0             0   \n",
      "Test_284            0            0            1            0             0   \n",
      "Test_285            0            0            0            0             0   \n",
      "Test_286            0            0            0            0             0   \n",
      "Test_287            0            0            0            0             0   \n",
      "Test_288            0            0            0            0             0   \n",
      "Test_289            0            0            0            0             0   \n",
      "Test_290            0            0            0            0             0   \n",
      "Test_291            0            1            3            0             0   \n",
      "Test_292            0            0            0            0             0   \n",
      "Test_293            0            1            0            0             0   \n",
      "Total             272         2930         4793          245            51   \n",
      "\n",
      "           ...    Condition_285  Condition_286  Condition_287  Condition_288  \\\n",
      "Test_1     ...                0              0              0              0   \n",
      "Test_2     ...                0              0              0              0   \n",
      "Test_3     ...                0              0              0              0   \n",
      "Test_4     ...                0              0              0              0   \n",
      "Test_5     ...                0              0              0              0   \n",
      "Test_6     ...                0              0              0              0   \n",
      "Test_7     ...                1              0              0              0   \n",
      "Test_8     ...                1              1              1              0   \n",
      "Test_9     ...                0              0              0              0   \n",
      "Test_10    ...                0              0              0              0   \n",
      "Test_11    ...                0              0              0              0   \n",
      "Test_12    ...                0              0              0              0   \n",
      "Test_13    ...                0              0              0              0   \n",
      "Test_14    ...                2              1              2              0   \n",
      "Test_15    ...                0              0              0              0   \n",
      "Test_16    ...                0              0              0              0   \n",
      "Test_17    ...                0              0              0              0   \n",
      "Test_18    ...                0              0              0              0   \n",
      "Test_19    ...                0              0              0              0   \n",
      "Test_20    ...                0              0              0              0   \n",
      "Test_21    ...                0              0              0              0   \n",
      "Test_22    ...                0              0              0              0   \n",
      "Test_23    ...                0              0              0              0   \n",
      "Test_24    ...                0              0              0              0   \n",
      "Test_25    ...                0              0              0              0   \n",
      "Test_26    ...                0              0              0              0   \n",
      "Test_27    ...                0              0              0              0   \n",
      "Test_28    ...                0              0              0              0   \n",
      "Test_29    ...                0              0              0              0   \n",
      "Test_30    ...                0              0              0              0   \n",
      "...        ...              ...            ...            ...            ...   \n",
      "Test_265   ...                9              5              2              0   \n",
      "Test_266   ...                2              0              0              0   \n",
      "Test_267   ...                0              1              0              0   \n",
      "Test_268   ...                0              0              0              0   \n",
      "Test_269   ...                0              0              0              0   \n",
      "Test_270   ...                1              0              0              0   \n",
      "Test_271   ...                1              0              1              0   \n",
      "Test_272   ...                0              3              0              0   \n",
      "Test_273   ...                0              0              0              0   \n",
      "Test_274   ...                0              0              0              0   \n",
      "Test_275   ...                1              1              0              0   \n",
      "Test_276   ...                0              0              0              0   \n",
      "Test_277   ...                0              0              0              0   \n",
      "Test_278   ...                0              0              0              0   \n",
      "Test_279   ...                0              0              0              0   \n",
      "Test_280   ...                0              0              1              0   \n",
      "Test_281   ...                0              0              0              0   \n",
      "Test_282   ...                0              3              0              0   \n",
      "Test_283   ...                0              0              0              0   \n",
      "Test_284   ...               25              0              0              0   \n",
      "Test_285   ...              293              1              0              0   \n",
      "Test_286   ...                0             82              0              0   \n",
      "Test_287   ...                0              2             68              0   \n",
      "Test_288   ...                0              0              0             97   \n",
      "Test_289   ...                0              0              0              0   \n",
      "Test_290   ...                1              9              1              0   \n",
      "Test_291   ...                2              2              0              0   \n",
      "Test_292   ...                0              0              0              0   \n",
      "Test_293   ...                0              0              0              0   \n",
      "Total      ...              628            483            183            149   \n",
      "\n",
      "          Condition_289  Condition_290  Condition_291  Condition_292  \\\n",
      "Test_1                0              0              0              0   \n",
      "Test_2                0              0              0              0   \n",
      "Test_3                0              0              0              0   \n",
      "Test_4                0              0              0              0   \n",
      "Test_5                0              0              0              0   \n",
      "Test_6                0              0              0              0   \n",
      "Test_7                0              0              0              0   \n",
      "Test_8                2              2              0              0   \n",
      "Test_9                0              0              0              0   \n",
      "Test_10               0              0              0              0   \n",
      "Test_11               0              0              0              0   \n",
      "Test_12               0              0              0              0   \n",
      "Test_13               0              0              0              0   \n",
      "Test_14               0              0              4              0   \n",
      "Test_15               0              0              0              0   \n",
      "Test_16               0              0              0              0   \n",
      "Test_17               0              0              0              0   \n",
      "Test_18               0              0              0              0   \n",
      "Test_19               0              0              0              0   \n",
      "Test_20               0              0              0              0   \n",
      "Test_21               0              0              0              0   \n",
      "Test_22               0              0              0              0   \n",
      "Test_23               0              0              0              0   \n",
      "Test_24               0              0              0              0   \n",
      "Test_25               0              0              0              0   \n",
      "Test_26               0              0              0              0   \n",
      "Test_27               0              0              0              0   \n",
      "Test_28               0              0              0              0   \n",
      "Test_29               0              0              0              0   \n",
      "Test_30               0              0              0              0   \n",
      "...                 ...            ...            ...            ...   \n",
      "Test_265              0              1              3              0   \n",
      "Test_266              0              0              1              0   \n",
      "Test_267              0              0              2              0   \n",
      "Test_268              0              0              0              0   \n",
      "Test_269              0              0              0              0   \n",
      "Test_270              0              0              0              0   \n",
      "Test_271              0              0              0              0   \n",
      "Test_272              0              0              0              0   \n",
      "Test_273              0              0              0              0   \n",
      "Test_274              0              0              0              0   \n",
      "Test_275              0              1              0              0   \n",
      "Test_276              0              0              0              0   \n",
      "Test_277              0              0              0              0   \n",
      "Test_278              0              0              0              0   \n",
      "Test_279              0              0              0              0   \n",
      "Test_280              0              0              0              0   \n",
      "Test_281              0              0              0              0   \n",
      "Test_282              2              0              0              0   \n",
      "Test_283              0              0              0              0   \n",
      "Test_284              0              0              0              0   \n",
      "Test_285              0              0              0              0   \n",
      "Test_286              0              0              0              0   \n",
      "Test_287              0              0              0              0   \n",
      "Test_288              0              0              0              0   \n",
      "Test_289              1              0              0              0   \n",
      "Test_290             16            132              0              0   \n",
      "Test_291              0              0           1492              0   \n",
      "Test_292              0              0              0             19   \n",
      "Test_293              0              0              0              0   \n",
      "Total                43            207           1690             22   \n",
      "\n",
      "          Condition_293   Total  \n",
      "Test_1                0     202  \n",
      "Test_2                0     174  \n",
      "Test_3                0     214  \n",
      "Test_4                0      64  \n",
      "Test_5                0     948  \n",
      "Test_6                0     278  \n",
      "Test_7                0    3337  \n",
      "Test_8                0    5450  \n",
      "Test_9                0      26  \n",
      "Test_10               0      24  \n",
      "Test_11               0    2916  \n",
      "Test_12               0    1071  \n",
      "Test_13               0     413  \n",
      "Test_14               0    3705  \n",
      "Test_15               0     215  \n",
      "Test_16               0     265  \n",
      "Test_17               0      20  \n",
      "Test_18               0     350  \n",
      "Test_19               0     528  \n",
      "Test_20               0       9  \n",
      "Test_21               0      67  \n",
      "Test_22               0      13  \n",
      "Test_23               0      85  \n",
      "Test_24               0      26  \n",
      "Test_25               0      66  \n",
      "Test_26               0     192  \n",
      "Test_27               0      33  \n",
      "Test_28               0      69  \n",
      "Test_29               0      89  \n",
      "Test_30               0      65  \n",
      "...                 ...     ...  \n",
      "Test_265              1   11991  \n",
      "Test_266              0    3338  \n",
      "Test_267              1    2373  \n",
      "Test_268              0      23  \n",
      "Test_269              0     174  \n",
      "Test_270              0    1428  \n",
      "Test_271              0     653  \n",
      "Test_272              0     317  \n",
      "Test_273              0      38  \n",
      "Test_274              0      36  \n",
      "Test_275              0     453  \n",
      "Test_276              0       7  \n",
      "Test_277              0     270  \n",
      "Test_278              0      22  \n",
      "Test_279              1      68  \n",
      "Test_280              0     802  \n",
      "Test_281              0     562  \n",
      "Test_282              0     112  \n",
      "Test_283              0      22  \n",
      "Test_284              0     621  \n",
      "Test_285              0     500  \n",
      "Test_286              0     135  \n",
      "Test_287              0      92  \n",
      "Test_288              0     140  \n",
      "Test_289              0       1  \n",
      "Test_290              0     257  \n",
      "Test_291              0    1766  \n",
      "Test_292              0      21  \n",
      "Test_293            112     135  \n",
      "Total               126  274164  \n",
      "\n",
      "[294 rows x 294 columns]\n",
      "\n",
      "        Metrics for Model: unspecified\n",
      "        ------------------------------------------------------\n",
      "        Accuracy Rate = 0.62122\n",
      "        Misclassification Rate = 0.37878\n",
      "        \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b7f885fd9234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_val_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-8bf65f44651d>\u001b[0m in \u001b[0;36mtrain_val_metrics\u001b[0;34m(grid, X_train, X_val, y_train, y_val)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulticlass_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mskplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "train_val_metrics(clf, embed_train, embed_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform combined_text\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=3, max_features=1000)\n",
    "docs = tfidf.fit_transform(X_train) \n",
    "\n",
    "# derive clusters\n",
    "clusters = KMeans(n_clusters=10)\n",
    "clusters.fit(docs)\n",
    "\n",
    "tsne = TSNEVisualizer()\n",
    "tsne.fit(docs, [\"c{}\".format(c) for c in clusters.labels_])\n",
    "tsne.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNEVisualizer()\n",
    "tsne.fit(docs, y_train)\n",
    "tsne.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalSentenceEmbeddingTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fetch_universal_sentence_embeddings(self, messages, verbose=0):\n",
    "        \"\"\"Fetches universal sentence embeddings from Google's\n",
    "        research paper https://arxiv.org/pdf/1803.11175.pdf.\n",
    "        INPUTS:\n",
    "        RETURNS:\n",
    "        \"\"\"\n",
    "        module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "        # Import the Universal Sentence Encoder's TF Hub module\n",
    "        embed = hub.Module(module_url)\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            message_embeddings = session.run(embed(messages))\n",
    "            embeddings = list()\n",
    "            for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "                if verbose:\n",
    "                    print(\"Message: {}\".format(messages[i]))\n",
    "                    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "                    message_embedding_snippet = \", \".join(\n",
    "                        (str(x) for x in message_embedding[:3]))\n",
    "                    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "                embeddings.append(message_embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"interface conforming, and allows use of fit_transform\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.fetch_universal_sentence_embeddings(messages=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'text': data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\", line 117, in _convert_to_compatible_tensor\n    tensor = tf.convert_to_tensor_or_indexed_slices(value, target.dtype)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1217, in convert_to_tensor_or_indexed_slices\n    value=value, dtype=dtype, name=name, as_ref=False)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1255, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1094, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 217, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 196, in constant\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 417, in make_tensor_proto\n    nparray = np.asarray(values, dtype=dtype)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\", line 492, in asarray\n    return array(a, dtype, copy=False, order=order)\nTypeError: data type not understood\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 265, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 230, in _fit\n    **fit_params_steps[name])\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 342, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 614, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 465, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"<ipython-input-46-239fb11a927a>\", line 33, in transform\n  File \"<ipython-input-46-239fb11a927a>\", line 16, in fetch_universal_sentence_embeddings\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py\", line 242, in __call__\n    tags=self._tags))\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py\", line 444, in _convert_dict_inputs\n    tensor_info_map)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\", line 148, in convert_dict_to_compatible_tensor\n    value, targets[key], error_prefix=\"Can't convert %r\" % key)\n  File \"/Users/washburp/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\", line 119, in _convert_to_compatible_tensor\n    raise TypeError(\"%s: %s\" % (error_prefix, e))\nTypeError: Can't convert 'text': data type not understood\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bf14c3cf5684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# fit pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert 'text': data type not understood"
     ]
    }
   ],
   "source": [
    "## Feature union with tfidf and embeddings\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# specify pipeline params\n",
    "params = {'clf__C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], \n",
    "          'clf__random_state': [7]}\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('encode', UniversalSentenceEmbeddingTransformer()),\n",
    "    ('clf', LinearSVC()) \n",
    "])\n",
    "\n",
    "# fit pipeline\n",
    "grid = GridSearchCV(pipeline, params, verbose=1, n_jobs=-1)\n",
    "grid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [Universal Sentence Encoder (paper)](https://arxiv.org/pdf/1803.11175.pdf)\n",
    "- [Google's Universal Sentence Encoder (TensorFlow Hub)](https://tfhub.dev/google/universal-sentence-encoder/2)\n",
    "- [Colab Notebook with Examples](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=pxe8MsCfFcy7)\n",
    "- [TensorFlow Embedding Documentation](https://www.tensorflow.org/guide/embedding)\n",
    "- [The Current Best of Universal Word Embeddings and Sentence Embeddings](https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a)\n",
    "- [Introducing state of the art text classification with universal language models](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
